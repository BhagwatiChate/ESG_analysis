{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710a928d",
   "metadata": {},
   "source": [
    "# ESG Pipeline Notebook\n",
    "Run all cells to produce the cross-company summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e154994a",
   "metadata": {},
   "source": [
    "\n",
    "## PDF Parsing Upgrade: Docling\n",
    "\n",
    "We now use **Docling** as the primary parser for higher-fidelity text extraction from PDFs (tables/columns often parse better).\n",
    "If Docling isn't available, we transparently fall back to PyPDF2.\n",
    "\n",
    "**Setup (outside this environment if needed):**\n",
    "```bash\n",
    "pip install docling docling-core pypdfium2\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261eaa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "# Prefer Docling if available; fall back to PyPDF2.\n",
    "def read_pdf_text(pdf_path: str):\n",
    "    \"\"\"\n",
    "    Returns: List[{\"page\": int, \"text\": str}]\n",
    "    \"\"\"\n",
    "    pages = []\n",
    "    # Try Docling\n",
    "    try:\n",
    "        from docling.document_converter import DocumentConverter\n",
    "        converter = DocumentConverter()\n",
    "        result = converter.convert(pdf_path)\n",
    "        doc = result.document\n",
    "\n",
    "        # Try different ways to get page text, since docling APIs can vary by version\n",
    "        for i, page in enumerate(getattr(doc, \"pages\", [])):\n",
    "            txt = \"\"\n",
    "            try:\n",
    "                # Some versions expose export_text()\n",
    "                if hasattr(page, \"export_text\"):\n",
    "                    txt = page.export_text() or \"\"\n",
    "                elif hasattr(page, \"to_text\"):\n",
    "                    txt = page.to_text() or \"\"\n",
    "                elif hasattr(page, \"content\"):\n",
    "                    # As a last resort, join textual content\n",
    "                    try:\n",
    "                        txt = \" \".join([c.text for c in page.content if getattr(c, \"text\", \"\")])\n",
    "                    except Exception:\n",
    "                        txt = \"\"\n",
    "            except Exception:\n",
    "                txt = \"\"\n",
    "            # Normalize docling text newlines/hyphenation similar to earlier logic\n",
    "            txt = re.sub(r\"(\\w)-\\n(\\w)\", r\"\\1\\2\", txt or \"\")\n",
    "            txt = txt.replace(\"\\r\", \"\\n\")\n",
    "            txt = re.sub(r\"[ \\t]+\", \" \", txt)\n",
    "            txt = re.sub(r\"\\n{3,}\", \"\\n\\n\", txt)\n",
    "            pages.append({\"page\": i+1, \"text\": (txt or \"\").strip()})\n",
    "        # If we collected any pages via Docling, return them\n",
    "        if pages:\n",
    "            return pages\n",
    "    except Exception as e:\n",
    "        # Docling not installed or failed; fall back below\n",
    "        pass\n",
    "\n",
    "    # Fall back to PyPDF2\n",
    "    try:\n",
    "        import PyPDF2\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            for i, page in enumerate(reader.pages):\n",
    "                try:\n",
    "                    raw = page.extract_text() or \"\"\n",
    "                except Exception:\n",
    "                    raw = \"\"\n",
    "                raw = re.sub(r\"(\\w)-\\n(\\w)\", r\"\\1\\2\", raw or \"\")\n",
    "                raw = raw.replace(\"\\r\", \"\\n\")\n",
    "                raw = re.sub(r\"[ \\t]+\", \" \", raw)\n",
    "                raw = re.sub(r\"\\n{3,}\", \"\\n\\n\", raw)\n",
    "                pages.append({\"page\": i+1, \"text\": (raw or \"\").strip()})\n",
    "    except Exception:\n",
    "        pass\n",
    "    return pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8db582f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Sector</th>\n",
       "      <th>ESG Topic</th>\n",
       "      <th>Extracted Claim</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Specificity Score</th>\n",
       "      <th>Greenwashing Risk Score</th>\n",
       "      <th>Doc</th>\n",
       "      <th>Page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company, Sector, ESG Topic, Extracted Claim, Sentiment Score, Specificity Score, Greenwashing Risk Score, Doc, Page]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# If running in a new environment, ensure dependencies:\n",
    "# pip install pandas numpy PyPDF2\n",
    "\n",
    "\n",
    "\n",
    "PDFS_DIR = r\"B:\\mandg\\ESG_Deliverables\\ESG_Deliverables_with_Summary\\data\"\n",
    "OUT_DIR  = r\"B:\\mandg\\ESG_Deliverables\\ESG_Deliverables_with_Summary\\outputs\"\n",
    "\n",
    "# Reuse the pipeline from this notebook cell\n",
    "\n",
    "import re, math\n",
    "import numpy as np\n",
    "try:\n",
    "    import PyPDF2\n",
    "    HAS_PYPDF2 = True\n",
    "except:\n",
    "    HAS_PYPDF2 = False\n",
    "\n",
    "def read_pdf_text(pdf_path):\n",
    "    pages = []\n",
    "    if not HAS_PYPDF2:\n",
    "        return pages\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            for i, page in enumerate(reader.pages):\n",
    "                try:\n",
    "                    raw = page.extract_text() or \"\"\n",
    "                except Exception:\n",
    "                    raw = \"\"\n",
    "                pages.append({\"page\": i+1, \"text\": raw})\n",
    "    except Exception:\n",
    "        return []\n",
    "    return pages\n",
    "\n",
    "def clean_text(t):\n",
    "    import re\n",
    "    if not t: return \"\"\n",
    "    t = re.sub(r\"(\\w)-\\n(\\w)\", r\"\\1\\2\", t)\n",
    "    t = t.replace(\"\\r\", \"\\n\")\n",
    "    t = re.sub(r\"[ \\t]+\", \" \", t)\n",
    "    t = re.sub(r\"\\n{3,}\", \"\\n\\n\", t)\n",
    "    return t.strip()\n",
    "\n",
    "def segment_text(text, max_chars=700):\n",
    "    import re\n",
    "    segments = []\n",
    "    paras = re.split(r\"\\n\\s*\\n\", text) if text else []\n",
    "    for p in paras:\n",
    "        p = p.strip()\n",
    "        if not p: \n",
    "            continue\n",
    "        if len(p) <= max_chars:\n",
    "            segments.append(p)\n",
    "        else:\n",
    "            words = p.split()\n",
    "            buf = []\n",
    "            cur_len = 0\n",
    "            for w in words:\n",
    "                buf.append(w)\n",
    "                cur_len += len(w) + 1\n",
    "                if cur_len > max_chars:\n",
    "                    segments.append(\" \".join(buf).strip())\n",
    "                    buf, cur_len = [], 0\n",
    "            if buf:\n",
    "                segments.append(\" \".join(buf).strip())\n",
    "    return segments\n",
    "\n",
    "ESG_KEYWORDS = {\n",
    "  \"GHG Emissions\": [\n",
    "    \"\\\\bghg\\\\b\",\n",
    "    \"scope\\\\s*1\",\n",
    "    \"scope\\\\s*2\",\n",
    "    \"scope\\\\s*3\",\n",
    "    \"\\\\bcarbon\\\\b\",\n",
    "    \"co2e\",\n",
    "    \"emission(s)?\",\n",
    "    \"net\\\\s*zero\",\n",
    "    \"decarboni[sz]e\",\n",
    "    \"\\\\btcf(d)?\\\\b\"\n",
    "  ],\n",
    "  \"Water & Effluents\": [\n",
    "    \"\\\\bwater\\\\b\",\n",
    "    \"effluent(s)?\",\n",
    "    \"wastewater\",\n",
    "    \"m3\",\n",
    "    \"withdrawal\",\n",
    "    \"discharge\"\n",
    "  ],\n",
    "  \"Waste Management\": [\n",
    "    \"\\\\bwaste\\\\b\",\n",
    "    \"landfill\",\n",
    "    \"recycl(e|ing)\",\n",
    "    \"circular\",\n",
    "    \"hazardous\"\n",
    "  ],\n",
    "  \"Energy Management\": [\n",
    "    \"\\\\benergy\\\\b\",\n",
    "    \"renewable\",\n",
    "    \"electricity\",\n",
    "    \"kwh\",\n",
    "    \"megawatt|mwh\"\n",
    "  ],\n",
    "  \"Biodiversity & Land Use\": [\n",
    "    \"\\\\bbiodiversit(y|ies)\\\\b\",\n",
    "    \"habitat\",\n",
    "    \"deforest\",\n",
    "    \"land use\"\n",
    "  ],\n",
    "  \"Labor Practices\": [\n",
    "    \"\\\\bsupply\\\\s*chain\\\\b\",\n",
    "    \"\\\\blabor\\\\b\",\n",
    "    \"collective bargaining\",\n",
    "    \"working hours\",\n",
    "    \"wages?\"\n",
    "  ],\n",
    "  \"Diversity, Equity & Inclusion\": [\n",
    "    \"\\\\bdiversit(y|ies)\\\\b\",\n",
    "    \"inclusion\",\n",
    "    \"gender\",\n",
    "    \"women in leadership\",\n",
    "    \"underrepresented\"\n",
    "  ],\n",
    "  \"Data Security & Privacy\": [\n",
    "    \"data\\\\s+(security|privacy|protection)\",\n",
    "    \"cyber\",\n",
    "    \"breach\",\n",
    "    \"gdpr\"\n",
    "  ],\n",
    "  \"Product Quality & Safety\": [\n",
    "    \"product\\\\s+(safety|quality|recall)\"\n",
    "  ],\n",
    "  \"Business Ethics & Compliance\": [\n",
    "    \"\\\\bethics?\\\\b\",\n",
    "    \"anti[-\\\\s]?corruption\",\n",
    "    \"bribery\",\n",
    "    \"compliance\",\n",
    "    \"whistleblow\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "def classify_topics(text):\n",
    "    t = text.lower()\n",
    "    hits = []\n",
    "    import re\n",
    "    for topic, patterns in ESG_KEYWORDS.items():\n",
    "        if any(re.search(p, t) for p in patterns):\n",
    "            hits.append(topic)\n",
    "    return hits\n",
    "\n",
    "CLAIM_PATTERNS = [\"\\\\b(we|the company|our)\\\\s+(will|plan|aim|target|commit|committed|intend)\\\\b\", \"\\\\bby\\\\s+20\\\\d{2}\\\\b\", \"\\\\b(increase|reduce|cut|lower|improve|achieve|reach)\\\\b\", \"\\\\b\\\\d+(\\\\.\\\\d+)?\\\\s*%\", \"\\\\bfrom a \\\\d{4} baseline\\\\b\", \"\\\\bsc(ope)?\\\\s*1\\\\b|\\\\bsc(ope)?\\\\s*2\\\\b|\\\\bsc(ope)?\\\\s*3\\\\b\"]\n",
    "\n",
    "def is_claim(text):\n",
    "    import re\n",
    "    t = text.lower()\n",
    "    return any(re.search(p, t) for p in CLAIM_PATTERNS)\n",
    "\n",
    "POS_WORDS = set(['leadership', 'achieve', 'reduction', 'renewable', 'reduced', 'delivered', 'met', 'exceeded', 'inclusive', 'improved', 'progress', 'improving', 'exceedance', 'strong', 'efficient', 'reduce', 'improve', 'target', 'exceed', 'robust', 'milestone'])\n",
    "NEG_WORDS = set(['worsening', 'failure', 'delays', 'risks', 'violate', 'risk', 'negative', 'violation', 'concern', 'incident', 'noncompliance', 'incidents', 'penalty', 'failed', 'worsen', 'problematic', 'breaches', 'penalties', 'concerns', 'breach', 'delay', 'non-compliance'])\n",
    "\n",
    "def sentiment_score(text):\n",
    "    import re, math\n",
    "    tokens = re.findall(r\"[a-zA-Z]+\", text.lower())\n",
    "    if not tokens:\n",
    "        return 0.5\n",
    "    pos = sum(1 for w in tokens if w in POS_WORDS)\n",
    "    neg = sum(1 for w in tokens if w in NEG_WORDS)\n",
    "    raw = pos - neg\n",
    "    return 1/(1 + math.exp(-raw))\n",
    "\n",
    "HEDGE_WORDS = set(['could', 'as', 'ambition', 'planning', 'consider', 'might', 'may', 'appropriate', 'seek', 'strive', 'potentially', 'towards', 'work', 'encourage', 'intend', 'explore', 'aim', 'ambitioned', 'plan', 'where', 'feasible'])\n",
    "METRIC_TERMS = set(['co2', 'kwh', 'tonnes', 'liters', 'gwh', 'co2e', 'm3', 'scope', 'baseline', 'tco2e', 'intensity', 'frequency', 'mwh', 'tons', 'water', 'emissions', 'rate', 'waste', 'energy'])\n",
    "\n",
    "def specificity_score(text):\n",
    "    import re\n",
    "    t = text.lower()\n",
    "    has_percent = bool(re.search(r\"\\d+(\\.\\d+)?\\s*%\", t))\n",
    "    has_year    = bool(re.search(r\"\\b(19|20)\\d{2}\\b\", t))\n",
    "    has_numbers = bool(re.search(r\"\\b\\d+(\\.\\d+)?\\b\", t))\n",
    "    has_by_year = bool(re.search(r\"\\bby\\s+(19|20)\\d{2}\\b\", t))\n",
    "    metrics     = sum(1 for m in METRIC_TERMS if m in t)\n",
    "    hedges      = sum(1 for h in HEDGE_WORDS if h in t)\n",
    "\n",
    "    base = 0.2\n",
    "    if has_numbers: base += 0.2\n",
    "    if has_percent: base += 0.2\n",
    "    if has_year:    base += 0.15\n",
    "    if has_by_year: base += 0.15\n",
    "    base += min(metrics, 5) * 0.03\n",
    "    base -= min(hedges, 5) * 0.05\n",
    "    return float(max(0.0, min(1.0, base)))\n",
    "\n",
    "def hedging_score(text):\n",
    "    t = text.lower()\n",
    "    hedges = sum(1 for h in HEDGE_WORDS if h in t)\n",
    "    return float(min(1.0, hedges / 5.0))\n",
    "\n",
    "def future_focus_score(text):\n",
    "    import re\n",
    "    t = text.lower()\n",
    "    future_hits = len(re.findall(r\"\\b(will|aim|plan|target|by\\s+20\\d{2}|net zero|2030|2050)\\b\", t))\n",
    "    past_hits   = len(re.findall(r\"\\b(achieved|delivered|completed|reached|reduced|improved|decreased)\\b\", t))\n",
    "    total = future_hits + past_hits\n",
    "    if total == 0: \n",
    "        return 0.5\n",
    "    return float(min(1.0, future_hits / total))\n",
    "\n",
    "def greenwashing_risk(sentiment, specificity, hedging, future_focus):\n",
    "    w_pos = 0.25; w_low_spec = 0.35; w_hedge = 0.25; w_future = 0.15\n",
    "    low_spec = 1 - specificity\n",
    "    return float(max(0.0, min(1.0, w_pos*sentiment + w_low_spec*low_spec + w_hedge*hedging + w_future*future_focus)))\n",
    "\n",
    "def derive_company_and_sector_from_filename(filename):\n",
    "    import os, re\n",
    "    base = os.path.basename(filename)\n",
    "    m = re.match(r\"([A-Za-z0-9&\\-\\s]+)_(Tech|Energy|Finance|Consumer|Industrial|Healthcare|Utilities|Materials)\", base, re.I)\n",
    "    if m: return (m.group(1).strip(), m.group(2).title())\n",
    "    name = os.path.splitext(base)[0]\n",
    "    return (name, \"Unknown\")\n",
    "\n",
    "def process_pdf(pdf_path):\n",
    "    company, sector = derive_company_and_sector_from_filename(pdf_path)\n",
    "    pages = read_pdf_text(pdf_path)\n",
    "    rows = []\n",
    "    for p in pages:\n",
    "        text = clean_text(p[\"text\"])\n",
    "        for seg in segment_text(text):\n",
    "            topics = classify_topics(seg)\n",
    "            if not topics:\n",
    "                continue\n",
    "            iscl = is_claim(seg)\n",
    "            sent = sentiment_score(seg)\n",
    "            spec = specificity_score(seg)\n",
    "            hedge = hedging_score(seg)\n",
    "            fut = future_focus_score(seg)\n",
    "            green = greenwashing_risk(sent, spec, hedge, fut)\n",
    "            rows.append({\n",
    "                \"Company\": company, \"Sector\": sector, \"Doc\": os.path.basename(pdf_path),\n",
    "                \"Page\": p[\"page\"], \"Text\": seg, \"Topics\": topics, \"IsClaim\": iscl,\n",
    "                \"Sentiment\": sent, \"Specificity\": spec, \"Hedging\": hedge, \"FutureFocus\": fut, \"Greenwash\": green\n",
    "            })\n",
    "    return rows\n",
    "\n",
    "def run_pipeline(pdf_paths):\n",
    "    import pandas as pd\n",
    "    all_rows = []\n",
    "    for pdf in pdf_paths:\n",
    "        if os.path.exists(pdf):\n",
    "            all_rows.extend(process_pdf(pdf))\n",
    "    if not all_rows:\n",
    "        return pd.DataFrame(columns=[\"Company\",\"Sector\",\"ESG Topic\",\"Extracted Claim\",\"Sentiment Score\",\"Specificity Score\",\"Greenwashing Risk Score\",\"Doc\",\"Page\"])\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    df_claims = df[(df[\"IsClaim\"] == True) & (df[\"Topics\"].map(lambda t: len(t)>0))].copy()\n",
    "    if df_claims.empty:\n",
    "        return pd.DataFrame(columns=[\"Company\",\"Sector\",\"ESG Topic\",\"Extracted Claim\",\"Sentiment Score\",\"Specificity Score\",\"Greenwashing Risk Score\",\"Doc\",\"Page\"])\n",
    "    df_claims[\"ESG Topic\"] = df_claims[\"Topics\"].map(lambda x: x[0] if x else \"\")\n",
    "    out = df_claims.rename(columns={\n",
    "        \"Text\":\"Extracted Claim\", \"Sentiment\":\"Sentiment Score\", \"Specificity\":\"Specificity Score\", \"Greenwash\":\"Greenwashing Risk Score\"\n",
    "    })[[\"Company\",\"Sector\",\"ESG Topic\",\"Extracted Claim\",\"Sentiment Score\",\"Specificity Score\",\"Greenwashing Risk Score\",\"Doc\",\"Page\"]]\n",
    "    out = out.drop_duplicates(subset=[\"Company\",\"Extracted Claim\",\"Page\"]).sort_values(by=[\"Company\",\"ESG Topic\",\"Specificity Score\"], ascending=[True,True,False])\n",
    "    return out\n",
    "\n",
    "pdfs = sorted([os.path.join(PDFS_DIR, f) for f in os.listdir(PDFS_DIR) if f.lower().endswith(\".pdf\")])\n",
    "df_summary = run_pipeline(pdfs)\n",
    "df_summary.to_csv(os.path.join(OUT_DIR, \"cross_company_esg_claim_summary.csv\"), index=False)\n",
    "df_summary.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94976664",
   "metadata": {},
   "source": [
    "\n",
    "## Groq-powered Metadata Extraction (Report-level)\n",
    "\n",
    "This section uses the **Groq Chat Completions API** to produce **structured metadata** for each PDF.\n",
    "It sends a compact context from the document (first/last pages and high-signal segments) and asks the model to return JSON following a schema.\n",
    "\n",
    "> **Setup**  \n",
    "> 1. Create a Groq API key and export it as an environment variable:\n",
    "> ```bash\n",
    "> export GROQ_API_KEY=your_key_here\n",
    "> ```\n",
    "> 2. (Optional) Install dependencies if you run outside ChatGPT:\n",
    "> ```bash\n",
    "> pip install requests pandas PyPDF2\n",
    "> ```\n",
    "> 3. Put your PDFs into `pdfs/`, then run this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d780ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with Groq: LSE_PAG_2024_business_esg.pdf\n",
      "Processing with Groq: Samsung_Electronics_Sustainability_Report_2025.pdf\n",
      "Processing with Groq: acer-incorporated_2023.pdf\n",
      "Processing with Groq: deutsche_esg.pdf\n",
      "Processing with Groq: intel_esg.pdf\n",
      "Processing with Groq: nippon_esg.pdf\n",
      "Processing with Groq: tata_steel_esg.pdf\n",
      "Saved: B:\\mandg\\ESG_Deliverables\\ESG_Deliverables_with_Summary\\outputs\\metadata_groq.json B:\\mandg\\ESG_Deliverables\\ESG_Deliverables_with_Summary\\outputs\\metadata_groq.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json, re, time, math\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PDFS_DIR = r\"B:\\mandg\\ESG_Deliverables\\ESG_Deliverables_with_Summary\\data\"\n",
    "OUT_DIR  = r\"B:\\mandg\\ESG_Deliverables\\ESG_Deliverables_with_Summary\\outputs\"\n",
    "\n",
    "# --- Minimal PDF text extraction (rely on previous section if already imported) ---\n",
    "try:\n",
    "    import PyPDF2\n",
    "    HAS_PYPDF2 = True\n",
    "except Exception:\n",
    "    HAS_PYPDF2 = False\n",
    "\n",
    "def read_pdf_text(pdf_path: str):\n",
    "    pages = []\n",
    "    if not HAS_PYPDF2:\n",
    "        return pages\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            for i, page in enumerate(reader.pages):\n",
    "                try:\n",
    "                    raw = page.extract_text() or \"\"\n",
    "                except Exception:\n",
    "                    raw = \"\"\n",
    "                pages.append({\"page\": i+1, \"text\": raw})\n",
    "    except Exception:\n",
    "        return []\n",
    "    return pages\n",
    "\n",
    "def clean_text(t: str) -> str:\n",
    "    if not t:\n",
    "        return \"\"\n",
    "    t = re.sub(r\"(\\w)-\\n(\\w)\", r\"\\1\\2\", t)\n",
    "    t = t.replace(\"\\r\", \"\\n\")\n",
    "    t = re.sub(r\"[ \\t]+\", \" \", t)\n",
    "    t = re.sub(r\"\\n{3,}\", \"\\n\\n\", t)\n",
    "    return t.strip()\n",
    "\n",
    "# --- Compact context builder ---\n",
    "def compact_context(pages: List[Dict[str,Any]], max_chars=6000) -> str:\n",
    "    \"\"\"Take first ~2 pages, last ~1 page, and up to 6 'dense' paragraphs from the middle.\"\"\"\n",
    "    if not pages:\n",
    "        return \"\"\n",
    "    txts = []\n",
    "    # first 2 pages\n",
    "    for p in pages[:2]:\n",
    "        txts.append(clean_text(p[\"text\"]))\n",
    "    # middle dense paragraphs (longest paragraphs heuristic)\n",
    "    mids = pages[2:-1] if len(pages) > 3 else []\n",
    "    paras = []\n",
    "    for p in mids:\n",
    "        for para in re.split(r\"\\n\\s*\\n\", clean_text(p[\"text\"])):\n",
    "            s = para.strip()\n",
    "            if len(s) > 150:\n",
    "                paras.append(s)\n",
    "    paras = sorted(paras, key=lambda s: -len(s))[:6]\n",
    "    txts.extend(paras)\n",
    "    # last page\n",
    "    txts.append(clean_text(pages[-1][\"text\"]))\n",
    "    joined = \"\\n\\n\".join([t for t in txts if t])\n",
    "    return joined[:max_chars]\n",
    "\n",
    "# --- Groq Chat Completions wrapper (OpenAI-compatible) ---\n",
    "def groq_chat_completion(messages, model=\"llama-3.1-70b-versatile\", temperature=0.1, max_tokens=1000, retries=2, timeout=60):\n",
    "    api_key = \"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\"\n",
    "    if not api_key:\n",
    "        print(\"⚠️ GROQ_API_KEY not set; skipping API call.\")\n",
    "        return Noneyyyyy\n",
    "    \n",
    "    url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"response_format\": {\"type\": \"json_object\"}\n",
    "    }\n",
    "    for attempt in range(retries+1):\n",
    "        try:\n",
    "            r = requests.post(url, headers=headers, json=payload, timeout=timeout)\n",
    "            if r.status_code == 200:\n",
    "                data = r.json()\n",
    "                content = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "                return content\n",
    "            else:\n",
    "                print(f\"Groq API status {r.status_code}: {r.text[:200]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Groq call failed (attempt {attempt+1}/{retries+1}): {e}\")\n",
    "        time.sleep(1 + attempt)\n",
    "    return None\n",
    "\n",
    "# --- JSON schema (report-level metadata) ---\n",
    "SCHEMA = {\n",
    "    \"company_name\": \"string\",\n",
    "    \"report_title\": \"string\",\n",
    "    \"report_year\": \"string|int\",\n",
    "    \"reporting_period\": \"string\",\n",
    "    \"sector_guess\": \"string\",\n",
    "    \"geography\": \"string\",\n",
    "    \"standards_referenced\": [\"SASB|GRI|TCFD|CDP|UNGC|Other\"],\n",
    "    \"scope_coverage\": {\"scope1\": \"bool\", \"scope2\": \"bool\", \"scope3\": \"bool\"},\n",
    "    \"material_topics\": [\"string\"],\n",
    "    \"targets\": [{\"topic\": \"string\", \"metric\": \"string\", \"baseline\": \"string\", \"target\": \"string\", \"target_year\": \"string\"}],\n",
    "    \"kpis\": [{\"name\": \"string\", \"value\": \"string\", \"unit\": \"string\", \"year\": \"string\"}],\n",
    "    \"assurance_audit\": \"string\",\n",
    "    \"risks_highlights\": [\"string\"],\n",
    "    \"notes\": \"string\",\n",
    "    \"_confidence\": 0.0\n",
    "}\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an ESG analyst assistant. Extract *concise, factual* report-level metadata from the provided context. \n",
    "Return strictly valid JSON following the provided schema. If uncertain, use empty strings, false, or []. Avoid hallucinating.\"\"\"\n",
    "\n",
    "USER_TEMPLATE = \"\"\"SCHEMA:\n",
    "{schema}\n",
    "\n",
    "CONTEXT (excerpted from the PDF; may be partial):\n",
    "---\n",
    "{context}\n",
    "---\n",
    "\n",
    "Rules:\n",
    "- Use short strings.\n",
    "- Keep arrays small (≤8 items each).\n",
    "- Prefer info explicitly stated in context.\n",
    "- If the company name or year is ambiguous, leave it blank.\n",
    "- Return only JSON (no markdown).\"\"\"\n",
    "\n",
    "def extract_metadata_for_pdf(pdf_path: str) -> Dict[str,Any]:\n",
    "    pages = read_pdf_text(pdf_path)\n",
    "    ctx = compact_context(pages)\n",
    "    if not ctx:\n",
    "        return {\"_error\": \"no_text\"}\n",
    "    user_msg = USER_TEMPLATE.format(schema=json.dumps(SCHEMA, indent=2), context=ctx)\n",
    "    content = groq_chat_completion([\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": user_msg}\n",
    "    ])\n",
    "    if not content:\n",
    "        return {\"_error\": \"no_api_or_failed\"}\n",
    "    try:\n",
    "        data = json.loads(content)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        # If model returns non-JSON, try to salvage\n",
    "        try:\n",
    "            content_stripped = content[content.find(\"{\"):content.rfind(\"}\")+1]\n",
    "            data = json.loads(content_stripped)\n",
    "            return data\n",
    "        except Exception:\n",
    "            return {\"_error\": f\"bad_json: {str(e)[:120]}\", \"_raw\": content[:500]}\n",
    "\n",
    "def run_groq_metadata():\n",
    "    pdfs = sorted([str(p) for p in Path(PDFS_DIR).glob(\"*.pdf\")])\n",
    "    results = {}\n",
    "    for p in pdfs:\n",
    "        print(f\"Processing with Groq: {Path(p).name}\")\n",
    "        md = extract_metadata_for_pdf(p)\n",
    "        results[Path(p).name] = md\n",
    "    # Save JSON\n",
    "    out_json = Path(OUT_DIR) / \"metadata_groq.json\"\n",
    "    out_json.write_text(json.dumps(results, indent=2))\n",
    "    # Also normalize to CSV (best-effort flatten)\n",
    "    rows = []\n",
    "    for fname, md in results.items():\n",
    "        base = {\"file\": fname}\n",
    "        if isinstance(md, dict):\n",
    "            for k, v in md.items():\n",
    "                if isinstance(v, (str, int, float, bool)) or v is None:\n",
    "                    base[k] = v\n",
    "            # join list-like fields succinctly\n",
    "            base[\"material_topics\"] = \", \".join(md.get(\"material_topics\", [])[:8]) if isinstance(md.get(\"material_topics\"), list) else \"\"\n",
    "            base[\"standards_referenced\"] = \", \".join(md.get(\"standards_referenced\", [])[:8]) if isinstance(md.get(\"standards_referenced\"), list) else \"\"\n",
    "            base[\"risks_highlights\"] = \", \".join(md.get(\"risks_highlights\", [])[:8]) if isinstance(md.get(\"risks_highlights\"), list) else \"\"\n",
    "            # summarize targets/kpis counts\n",
    "            base[\"targets_count\"] = len(md.get(\"targets\", [])) if isinstance(md.get(\"targets\"), list) else 0\n",
    "            base[\"kpis_count\"] = len(md.get(\"kpis\", [])) if isinstance(md.get(\"kpis\"), list) else 0\n",
    "        rows.append(base)\n",
    "    df = pd.DataFrame(rows)\n",
    "    out_csv = Path(OUT_DIR) / \"metadata_groq.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(\"Saved:\", out_json, out_csv)\n",
    "    return results\n",
    "\n",
    "_ = run_groq_metadata()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736bf72b",
   "metadata": {},
   "source": [
    "\n",
    "### Parser robustness + diagnostics\n",
    "\n",
    "We now try multiple backends in order: **Docling → pdfplumber → PyPDF2 → (optional OCR)**.\n",
    "A quick diagnostics table will show per-file page and character counts, so you can see if a PDF is image-only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf14277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 16:00:53,951 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:00:53,967 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:00:55,217 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:02,418 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:02,418 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:03,202 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:03,202 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:01:03,217 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:01:03,225 - WARNING - Cannot set gray stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:01:03,225 - WARNING - Cannot set gray stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:01:03,231 - WARNING - Cannot set gray stroke color because /'P5' is an invalid float value\n",
      "2025-09-25 16:01:03,239 - WARNING - Cannot set gray stroke color because /'P6' is an invalid float value\n",
      "2025-09-25 16:01:03,239 - WARNING - Cannot set gray stroke color because /'P7' is an invalid float value\n",
      "2025-09-25 16:01:03,239 - WARNING - Cannot set gray stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:01:05,017 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:05,017 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:01:05,034 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:01:05,041 - WARNING - Cannot set gray stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:01:05,041 - WARNING - Cannot set gray stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:01:07,200 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:07,200 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:01:07,215 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:01:07,220 - WARNING - Cannot set gray stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:01:07,226 - WARNING - Cannot set gray stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:01:17,151 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:17,157 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:17,167 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:17,174 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:17,317 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:18,217 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:18,217 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:01:18,226 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:01:19,081 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:19,085 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:01:19,088 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:01:19,090 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:01:20,494 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:20,496 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:20,506 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:20,513 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:20,817 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:20,817 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:01:20,817 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:01:20,951 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:22,968 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:01:22,968 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:08:06,891 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:08:07,091 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:08:07,254 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:10:17,527 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:10:17,705 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:10:17,928 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:12:39,912 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:12:39,946 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:12:39,969 - WARNING - Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:12:40,001 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:12:40,013 - WARNING - Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:12:40,014 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:12:40,031 - WARNING - Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
      "2025-09-25 16:12:40,058 - WARNING - Cannot set gray non-stroke color because /'P6' is an invalid float value\n",
      "2025-09-25 16:12:40,112 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:12:40,131 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:12:40,148 - WARNING - Cannot set gray non-stroke color because /'P7' is an invalid float value\n",
      "2025-09-25 16:12:40,246 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:12:40,346 - WARNING - Cannot set gray non-stroke color because /'P9' is an invalid float value\n",
      "2025-09-25 16:12:40,364 - WARNING - Cannot set gray non-stroke color because /'P10' is an invalid float value\n",
      "2025-09-25 16:12:40,381 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:12:40,381 - WARNING - Cannot set gray non-stroke color because /'P11' is an invalid float value\n",
      "2025-09-25 16:12:40,399 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:12:49,281 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:12:49,297 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:12:49,322 - WARNING - Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:12:49,360 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:12:49,372 - WARNING - Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:12:49,374 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:12:49,386 - WARNING - Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
      "2025-09-25 16:12:49,404 - WARNING - Cannot set gray non-stroke color because /'P6' is an invalid float value\n",
      "2025-09-25 16:12:49,444 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 16:12:49,447 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:12:49,463 - WARNING - Cannot set gray non-stroke color because /'P7' is an invalid float value\n",
      "2025-09-25 16:12:49,547 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:12:49,635 - WARNING - Cannot set gray non-stroke color because /'P9' is an invalid float value\n",
      "2025-09-25 16:12:49,647 - WARNING - Cannot set gray non-stroke color because /'P10' is an invalid float value\n",
      "2025-09-25 16:12:49,660 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:12:49,668 - WARNING - Cannot set gray non-stroke color because /'P11' is an invalid float value\n",
      "2025-09-25 16:12:49,675 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:12:50,629 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:12:50,645 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:12:50,668 - WARNING - Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:12:50,700 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:12:50,711 - WARNING - Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:12:50,712 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:12:50,725 - WARNING - Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
      "2025-09-25 16:12:50,747 - WARNING - Cannot set gray non-stroke color because /'P6' is an invalid float value\n",
      "2025-09-25 16:12:50,775 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:12:50,787 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:12:50,798 - WARNING - Cannot set gray non-stroke color because /'P7' is an invalid float value\n",
      "2025-09-25 16:12:50,881 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:12:50,964 - WARNING - Cannot set gray non-stroke color because /'P9' is an invalid float value\n",
      "2025-09-25 16:12:50,989 - WARNING - Cannot set gray non-stroke color because /'P10' is an invalid float value\n",
      "2025-09-25 16:12:51,005 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:12:51,007 - WARNING - Cannot set gray non-stroke color because /'P11' is an invalid float value\n",
      "2025-09-25 16:12:51,021 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>pages</th>\n",
       "      <th>total_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acer-incorporated_2023.pdf</td>\n",
       "      <td>153</td>\n",
       "      <td>611933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deutsche_esg.pdf</td>\n",
       "      <td>737</td>\n",
       "      <td>2766179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intel_esg.pdf</td>\n",
       "      <td>492</td>\n",
       "      <td>1224657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>50</td>\n",
       "      <td>137411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nippon_esg.pdf</td>\n",
       "      <td>34</td>\n",
       "      <td>307887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samsung_Electronics_Sustainability_Report_2025...</td>\n",
       "      <td>87</td>\n",
       "      <td>380782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tata_steel_esg.pdf</td>\n",
       "      <td>62</td>\n",
       "      <td>191166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  pages  total_chars\n",
       "0                         acer-incorporated_2023.pdf    153       611933\n",
       "1                                   deutsche_esg.pdf    737      2766179\n",
       "2                                      intel_esg.pdf    492      1224657\n",
       "3                      LSE_PAG_2024_business_esg.pdf     50       137411\n",
       "4                                     nippon_esg.pdf     34       307887\n",
       "5  Samsung_Electronics_Sustainability_Report_2025...     87       380782\n",
       "6                                 tata_steel_esg.pdf     62       191166"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import re, os, io, warnings\n",
    "\n",
    "def _clean_text_basic(t: str) -> str:\n",
    "    if not t: return \"\"\n",
    "    t = re.sub(r\"(\\w)-\\n(\\w)\", r\"\\1\\2\", t)\n",
    "    t = t.replace(\"\\r\", \"\\n\")\n",
    "    t = re.sub(r\"[ \\t]+\", \" \", t)\n",
    "    t = re.sub(r\"\\n{3,}\", \"\\n\\n\", t)\n",
    "    return t.strip()\n",
    "\n",
    "def _try_docling(pdf_path: str):\n",
    "    pages = []\n",
    "    try:\n",
    "        from docling.document_converter import DocumentConverter\n",
    "        converter = DocumentConverter()\n",
    "        result = converter.convert(pdf_path)\n",
    "        doc = result.document\n",
    "        got = False\n",
    "        for i, page in enumerate(getattr(doc, \"pages\", [])):\n",
    "            txt = \"\"\n",
    "            try:\n",
    "                if hasattr(page, \"export_text\"):\n",
    "                    txt = page.export_text() or \"\"\n",
    "                elif hasattr(page, \"to_text\"):\n",
    "                    txt = page.to_text() or \"\"\n",
    "                elif hasattr(page, \"content\"):\n",
    "                    try:\n",
    "                        txt = \" \".join([c.text for c in page.content if getattr(c, \"text\", \"\")])\n",
    "                    except Exception:\n",
    "                        txt = \"\"\n",
    "            except Exception:\n",
    "                txt = \"\"\n",
    "            txt = _clean_text_basic(txt or \"\")\n",
    "            pages.append({\"page\": i+1, \"text\": txt})\n",
    "            if txt.strip(): got = True\n",
    "        if got:\n",
    "            return pages\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "def _try_pdfplumber(pdf_path: str):\n",
    "    pages = []\n",
    "    try:\n",
    "        import pdfplumber\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for i, p in enumerate(pdf.pages):\n",
    "                try:\n",
    "                    txt = p.extract_text() or \"\"\n",
    "                except Exception:\n",
    "                    txt = \"\"\n",
    "                pages.append({\"page\": i+1, \"text\": _clean_text_basic(txt)})\n",
    "        if any(pg[\"text\"] for pg in pages):\n",
    "            return pages\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "def _try_pypdf2(pdf_path: str):\n",
    "    pages = []\n",
    "    try:\n",
    "        import PyPDF2\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            for i, page in enumerate(reader.pages):\n",
    "                try:\n",
    "                    raw = page.extract_text() or \"\"\n",
    "                except Exception:\n",
    "                    raw = \"\"\n",
    "                pages.append({\"page\": i+1, \"text\": _clean_text_basic(raw)})\n",
    "        if any(pg[\"text\"] for pg in pages):\n",
    "            return pages\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "def _try_ocr(pdf_path: str, max_pages=10):\n",
    "    \"\"\"Very slow; only used if pytesseract + pdf2image are installed and no other parser worked.\"\"\"\n",
    "    pages = []\n",
    "    try:\n",
    "        import pytesseract\n",
    "        from pdf2image import convert_from_path\n",
    "    except Exception:\n",
    "        return []\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path, dpi=200)\n",
    "        for i, img in enumerate(images[:max_pages]):\n",
    "            try:\n",
    "                txt = pytesseract.image_to_string(img) or \"\"\n",
    "            except Exception:\n",
    "                txt = \"\"\n",
    "            pages.append({\"page\": i+1, \"text\": _clean_text_basic(txt)})\n",
    "        if any(pg[\"text\"] for pg in pages):\n",
    "            return pages\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "def read_pdf_text(pdf_path: str):\n",
    "    # Try in order: docling -> pdfplumber -> PyPDF2 -> OCR\n",
    "    for fn in (_try_docling, _try_pdfplumber, _try_pypdf2, _try_ocr):\n",
    "        pages = fn(pdf_path)\n",
    "        if any(pg.get(\"text\") for pg in pages):\n",
    "            return pages\n",
    "    return []\n",
    "\n",
    "def parse_diagnostics(pdf_dir: str):\n",
    "    from pathlib import Path\n",
    "    rows = []\n",
    "    for p in sorted(Path(pdf_dir).glob(\"*.pdf\")):\n",
    "        pages = read_pdf_text(str(p))\n",
    "        total_chars = sum(len(pg.get(\"text\",\"\")) for pg in pages)\n",
    "        rows.append({\"file\": p.name, \"pages\": len(pages), \"total_chars\": total_chars})\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(rows)\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "PDFS_DIR = r\"B:\\mandg\\ESG_Deliverables\\ESG_Deliverables_with_Summary\\data\"\n",
    "# OUT_DIR  = r\"B:\\mandg\\ESG_Deliverables\\ESG_Deliverables_with_Summary\\outputs\"\n",
    "\n",
    "parse_diagnostics(PDFS_DIR);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7255ef0",
   "metadata": {},
   "source": [
    "\n",
    "### Fallback behavior (no claims found)\n",
    "\n",
    "If a PDF has text but no explicit *claim* matches, we will still output the **top topic segments** by specificity\n",
    "so the summary table is not empty and you have material to review.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3d82a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 16:14:10,076 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:10,081 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:11,647 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:17,481 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:17,495 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:18,755 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:18,764 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:14:18,777 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:14:18,796 - WARNING - Cannot set gray stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:14:18,799 - WARNING - Cannot set gray stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:14:18,799 - WARNING - Cannot set gray stroke color because /'P5' is an invalid float value\n",
      "2025-09-25 16:14:18,807 - WARNING - Cannot set gray stroke color because /'P6' is an invalid float value\n",
      "2025-09-25 16:14:18,807 - WARNING - Cannot set gray stroke color because /'P7' is an invalid float value\n",
      "2025-09-25 16:14:18,817 - WARNING - Cannot set gray stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:14:20,631 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:20,631 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:14:20,651 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:14:20,656 - WARNING - Cannot set gray stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:14:20,664 - WARNING - Cannot set gray stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:14:22,781 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:22,797 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:14:22,802 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:14:22,806 - WARNING - Cannot set gray stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:14:22,816 - WARNING - Cannot set gray stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:14:31,436 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:31,436 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:31,451 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:31,457 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:31,614 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:32,448 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:32,448 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:14:32,464 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:14:33,531 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:33,531 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:14:33,543 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:14:33,545 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:14:35,951 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:35,957 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:35,964 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:35,973 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:36,314 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:36,314 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:14:36,314 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:14:36,436 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:38,087 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:14:38,093 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:23:04,382 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:23:04,611 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:23:04,811 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:26:28,954 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:26:29,114 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:26:29,347 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:31:58,962 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:31:59,015 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:31:59,065 - WARNING - Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:31:59,151 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:31:59,187 - WARNING - Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:31:59,192 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:31:59,229 - WARNING - Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
      "2025-09-25 16:31:59,273 - WARNING - Cannot set gray non-stroke color because /'P6' is an invalid float value\n",
      "2025-09-25 16:31:59,346 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:31:59,372 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:31:59,396 - WARNING - Cannot set gray non-stroke color because /'P7' is an invalid float value\n",
      "2025-09-25 16:31:59,604 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:31:59,765 - WARNING - Cannot set gray non-stroke color because /'P9' is an invalid float value\n",
      "2025-09-25 16:31:59,796 - WARNING - Cannot set gray non-stroke color because /'P10' is an invalid float value\n",
      "2025-09-25 16:31:59,829 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:31:59,837 - WARNING - Cannot set gray non-stroke color because /'P11' is an invalid float value\n",
      "2025-09-25 16:31:59,856 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:32:14,520 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:32:14,559 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:32:14,597 - WARNING - Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:32:14,663 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:32:14,688 - WARNING - Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:32:14,693 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:32:14,738 - WARNING - Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
      "2025-09-25 16:32:14,794 - WARNING - Cannot set gray non-stroke color because /'P6' is an invalid float value\n",
      "2025-09-25 16:32:14,869 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 16:32:14,894 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:32:14,917 - WARNING - Cannot set gray non-stroke color because /'P7' is an invalid float value\n",
      "2025-09-25 16:32:15,097 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:32:15,228 - WARNING - Cannot set gray non-stroke color because /'P9' is an invalid float value\n",
      "2025-09-25 16:32:15,250 - WARNING - Cannot set gray non-stroke color because /'P10' is an invalid float value\n",
      "2025-09-25 16:32:15,273 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:32:15,281 - WARNING - Cannot set gray non-stroke color because /'P11' is an invalid float value\n",
      "2025-09-25 16:32:15,296 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:32:16,489 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:32:16,512 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:32:16,541 - WARNING - Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:32:16,585 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:32:16,601 - WARNING - Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:32:16,604 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:32:16,628 - WARNING - Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
      "2025-09-25 16:32:16,656 - WARNING - Cannot set gray non-stroke color because /'P6' is an invalid float value\n",
      "2025-09-25 16:32:16,702 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:32:16,719 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:32:16,735 - WARNING - Cannot set gray non-stroke color because /'P7' is an invalid float value\n",
      "2025-09-25 16:32:16,870 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:32:16,996 - WARNING - Cannot set gray non-stroke color because /'P9' is an invalid float value\n",
      "2025-09-25 16:32:17,014 - WARNING - Cannot set gray non-stroke color because /'P10' is an invalid float value\n",
      "2025-09-25 16:32:17,030 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:32:17,036 - WARNING - Cannot set gray non-stroke color because /'P11' is an invalid float value\n",
      "2025-09-25 16:32:17,048 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Sector</th>\n",
       "      <th>ESG Topic</th>\n",
       "      <th>Extracted Claim</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Specificity Score</th>\n",
       "      <th>Greenwashing Risk Score</th>\n",
       "      <th>Doc</th>\n",
       "      <th>Page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Biodiversity &amp; Land Use</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.645</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Business Ethics &amp; Compliance</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.545</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Data Security &amp; Privacy</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.565</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Diversity, Equity &amp; Inclusion</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.637</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Diversity, Equity &amp; Inclusion</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.622</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Diversity, Equity &amp; Inclusion</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.650</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Diversity, Equity &amp; Inclusion</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.713</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>GHG Emissions</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.363</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>GHG Emissions</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.441</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>GHG Emissions</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.575</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>GHG Emissions</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.538</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>GHG Emissions</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.563</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>GHG Emissions</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.695</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>GHG Emissions</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.695</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>GHG Emissions</td>\n",
       "      <td>Our mortgage portfolio The scale of reduction ...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.711</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>GHG Emissions</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.419</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>GHG Emissions</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.736</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>GHG Emissions</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.667</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>GHG Emissions</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.772</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>LSE_PAG_2024_business_esg</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>GHG Emissions</td>\n",
       "      <td>Home Introduction About Paragon Environment So...</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.630</td>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Company   Sector                      ESG Topic  \\\n",
       "609  LSE_PAG_2024_business_esg  Unknown        Biodiversity & Land Use   \n",
       "632  LSE_PAG_2024_business_esg  Unknown   Business Ethics & Compliance   \n",
       "633  LSE_PAG_2024_business_esg  Unknown        Data Security & Privacy   \n",
       "630  LSE_PAG_2024_business_esg  Unknown  Diversity, Equity & Inclusion   \n",
       "629  LSE_PAG_2024_business_esg  Unknown  Diversity, Equity & Inclusion   \n",
       "626  LSE_PAG_2024_business_esg  Unknown  Diversity, Equity & Inclusion   \n",
       "628  LSE_PAG_2024_business_esg  Unknown  Diversity, Equity & Inclusion   \n",
       "618  LSE_PAG_2024_business_esg  Unknown                  GHG Emissions   \n",
       "613  LSE_PAG_2024_business_esg  Unknown                  GHG Emissions   \n",
       "611  LSE_PAG_2024_business_esg  Unknown                  GHG Emissions   \n",
       "622  LSE_PAG_2024_business_esg  Unknown                  GHG Emissions   \n",
       "623  LSE_PAG_2024_business_esg  Unknown                  GHG Emissions   \n",
       "608  LSE_PAG_2024_business_esg  Unknown                  GHG Emissions   \n",
       "615  LSE_PAG_2024_business_esg  Unknown                  GHG Emissions   \n",
       "621  LSE_PAG_2024_business_esg  Unknown                  GHG Emissions   \n",
       "607  LSE_PAG_2024_business_esg  Unknown                  GHG Emissions   \n",
       "625  LSE_PAG_2024_business_esg  Unknown                  GHG Emissions   \n",
       "616  LSE_PAG_2024_business_esg  Unknown                  GHG Emissions   \n",
       "614  LSE_PAG_2024_business_esg  Unknown                  GHG Emissions   \n",
       "620  LSE_PAG_2024_business_esg  Unknown                  GHG Emissions   \n",
       "\n",
       "                                       Extracted Claim  Sentiment Score  \\\n",
       "609  Home Introduction About Paragon Environment So...            0.269   \n",
       "632  Home Introduction About Paragon Environment So...            0.007   \n",
       "633  Home Introduction About Paragon Environment So...            0.000   \n",
       "630  Home Introduction About Paragon Environment So...            0.998   \n",
       "629  Home Introduction About Paragon Environment So...            0.998   \n",
       "626  Home Introduction About Paragon Environment So...            0.881   \n",
       "628  Home Introduction About Paragon Environment So...            0.993   \n",
       "618  Home Introduction About Paragon Environment So...            0.731   \n",
       "613  Home Introduction About Paragon Environment So...            0.881   \n",
       "611  Home Introduction About Paragon Environment So...            0.999   \n",
       "622  Home Introduction About Paragon Environment So...            1.000   \n",
       "623  Home Introduction About Paragon Environment So...            1.000   \n",
       "608  Home Introduction About Paragon Environment So...            1.000   \n",
       "615  Home Introduction About Paragon Environment So...            1.000   \n",
       "621  Our mortgage portfolio The scale of reduction ...            1.000   \n",
       "607  Home Introduction About Paragon Environment So...            0.881   \n",
       "625  Home Introduction About Paragon Environment So...            0.993   \n",
       "616  Home Introduction About Paragon Environment So...            1.000   \n",
       "614  Home Introduction About Paragon Environment So...            1.000   \n",
       "620  Home Introduction About Paragon Environment So...            0.731   \n",
       "\n",
       "     Specificity Score  Greenwashing Risk Score  \\\n",
       "609               0.35                    0.645   \n",
       "632               0.53                    0.545   \n",
       "633               0.53                    0.565   \n",
       "630               0.75                    0.637   \n",
       "629               0.65                    0.622   \n",
       "626               0.63                    0.650   \n",
       "628               0.53                    0.713   \n",
       "618               0.97                    0.363   \n",
       "613               0.94                    0.441   \n",
       "611               0.90                    0.575   \n",
       "622               0.89                    0.538   \n",
       "623               0.84                    0.563   \n",
       "608               0.80                    0.695   \n",
       "615               0.80                    0.695   \n",
       "621               0.80                    0.711   \n",
       "607               0.79                    0.419   \n",
       "625               0.71                    0.736   \n",
       "616               0.70                    0.667   \n",
       "614               0.65                    0.772   \n",
       "620               0.65                    0.630   \n",
       "\n",
       "                               Doc  Page  \n",
       "609  LSE_PAG_2024_business_esg.pdf    12  \n",
       "632  LSE_PAG_2024_business_esg.pdf    47  \n",
       "633  LSE_PAG_2024_business_esg.pdf    48  \n",
       "630  LSE_PAG_2024_business_esg.pdf    40  \n",
       "629  LSE_PAG_2024_business_esg.pdf    39  \n",
       "626  LSE_PAG_2024_business_esg.pdf    33  \n",
       "628  LSE_PAG_2024_business_esg.pdf    38  \n",
       "618  LSE_PAG_2024_business_esg.pdf    21  \n",
       "613  LSE_PAG_2024_business_esg.pdf    16  \n",
       "611  LSE_PAG_2024_business_esg.pdf    14  \n",
       "622  LSE_PAG_2024_business_esg.pdf    25  \n",
       "623  LSE_PAG_2024_business_esg.pdf    26  \n",
       "608  LSE_PAG_2024_business_esg.pdf    10  \n",
       "615  LSE_PAG_2024_business_esg.pdf    18  \n",
       "621  LSE_PAG_2024_business_esg.pdf    24  \n",
       "607  LSE_PAG_2024_business_esg.pdf     9  \n",
       "625  LSE_PAG_2024_business_esg.pdf    29  \n",
       "616  LSE_PAG_2024_business_esg.pdf    19  \n",
       "614  LSE_PAG_2024_business_esg.pdf    17  \n",
       "620  LSE_PAG_2024_business_esg.pdf    23  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: B:\\mandg\\ESG_Deliverables\\ESG_Deliverables_with_Summary\\outputs\\cross_company_esg_claim_summary.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, re, math, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Reuse classify_topics, sentiment_score, specificity_score, etc. from earlier cells.\n",
    "# If they're not in memory (fresh kernel), you may need to re-run the earlier pipeline cells first.\n",
    "\n",
    "def _collect_segments(pdf_path: str):\n",
    "    pages = read_pdf_text(pdf_path)\n",
    "    segs = []\n",
    "    for p in pages:\n",
    "        text = p[\"text\"]\n",
    "        # simple segmenter: split paragraphs\n",
    "        paras = re.split(r\"\\n\\s*\\n\", text) if text else []\n",
    "        for para in paras:\n",
    "            s = para.strip()\n",
    "            if not s:\n",
    "                continue\n",
    "            segs.append((p[\"page\"], s))\n",
    "    return segs\n",
    "\n",
    "def run_pipeline_with_fallback(pdf_dir: str, out_csv: str):\n",
    "    pdfs = [str(p) for p in Path(pdf_dir).glob(\"*.pdf\")]\n",
    "    rows = []\n",
    "    for pdf in pdfs:\n",
    "        company, sector = (\"Unknown\", \"Unknown\")\n",
    "        try:\n",
    "            from os.path import basename, splitext\n",
    "            base = basename(pdf)\n",
    "            name = splitext(base)[0]\n",
    "            company = name\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # gather segments\n",
    "        segs = _collect_segments(pdf)\n",
    "        found_claim = False\n",
    "        topic_rows = []\n",
    "\n",
    "        for page, seg in segs:\n",
    "            topics = classify_topics(seg) if 'classify_topics' in globals() else []\n",
    "            if not topics:\n",
    "                continue\n",
    "            sent = sentiment_score(seg) if 'sentiment_score' in globals() else 0.5\n",
    "            spec = specificity_score(seg) if 'specificity_score' in globals() else 0.2\n",
    "            iscl = is_claim(seg) if 'is_claim' in globals() else False\n",
    "            green = greenwashing_risk(sent, spec, hedging_score(seg), future_focus_score(seg)) if 'greenwashing_risk' in globals() else 0.5\n",
    "\n",
    "            if iscl:\n",
    "                found_claim = True\n",
    "                rows.append({\n",
    "                    \"Company\": company, \"Sector\": sector, \"ESG Topic\": topics[0],\n",
    "                    \"Extracted Claim\": seg[:600],\n",
    "                    \"Sentiment Score\": round(sent,3), \"Specificity Score\": round(spec,3),\n",
    "                    \"Greenwashing Risk Score\": round(green,3),\n",
    "                    \"Doc\": os.path.basename(pdf), \"Page\": page\n",
    "                })\n",
    "            else:\n",
    "                topic_rows.append({\n",
    "                    \"Company\": company, \"Sector\": sector, \"ESG Topic\": topics[0],\n",
    "                    \"Extracted Claim\": seg[:600],\n",
    "                    \"Sentiment Score\": round(sent,3), \"Specificity Score\": round(spec,3),\n",
    "                    \"Greenwashing Risk Score\": round(green,3),\n",
    "                    \"Doc\": os.path.basename(pdf), \"Page\": page\n",
    "                }) \n",
    "\n",
    "        if not found_claim and topic_rows:\n",
    "            # take top N by specificity as fallback surface\n",
    "            topic_rows.sort(key=lambda r: (-r[\"Specificity Score\"], r[\"ESG Topic\"]))\n",
    "            rows.extend(topic_rows[:10])\n",
    "\n",
    "    df = pd.DataFrame(rows).drop_duplicates(subset=[\"Company\",\"Extracted Claim\",\"Page\"])\n",
    "    if not df.empty:\n",
    "        df = df.sort_values(by=[\"Company\",\"ESG Topic\",\"Specificity Score\"], ascending=[True, True, False])\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    display(df.head(20))\n",
    "    return df\n",
    "\n",
    "OUT_CSV = r\"B:\\mandg\\ESG_Deliverables\\ESG_Deliverables_with_Summary\\outputs\\cross_company_esg_claim_summary.csv\"\n",
    "_ = run_pipeline_with_fallback(PDFS_DIR, OUT_CSV)\n",
    "print(\"Wrote:\", OUT_CSV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e712977a",
   "metadata": {},
   "source": [
    "\n",
    "## BRSR / SEBI-Core Flow (Structure-aware parsing for Indian CSR/ESG reports)\n",
    "\n",
    "This step adds structure-aware rules for **Business Responsibility and Sustainability Report (BRSR)** style PDFs.\n",
    "It extracts company/FY, **assurance provider**, reporting boundary, plants/offices, export %, key employee totals,\n",
    "POSH complaints, **material issues**, and standards referenced.  \n",
    "Outputs: `out/brsr_metadata.json` and `out/brsr_metadata.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c59c45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 16:35:49,205 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:35:49,206 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:35:50,240 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:35:56,839 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:35:56,839 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:35:57,788 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:35:57,789 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:35:57,801 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:35:57,815 - WARNING - Cannot set gray stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:35:57,817 - WARNING - Cannot set gray stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:35:57,818 - WARNING - Cannot set gray stroke color because /'P5' is an invalid float value\n",
      "2025-09-25 16:35:57,824 - WARNING - Cannot set gray stroke color because /'P6' is an invalid float value\n",
      "2025-09-25 16:35:57,828 - WARNING - Cannot set gray stroke color because /'P7' is an invalid float value\n",
      "2025-09-25 16:35:57,834 - WARNING - Cannot set gray stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:35:59,289 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:35:59,289 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:35:59,303 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:35:59,309 - WARNING - Cannot set gray stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:35:59,309 - WARNING - Cannot set gray stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:36:01,439 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:36:01,439 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:36:01,452 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:36:01,458 - WARNING - Cannot set gray stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:36:01,461 - WARNING - Cannot set gray stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:36:11,489 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:36:11,489 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:36:11,511 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:36:11,514 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:36:11,792 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:36:13,013 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:36:13,013 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:36:13,023 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:36:13,889 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:36:13,889 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:36:13,902 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:36:13,903 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:36:15,689 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:36:15,689 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:36:15,710 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:36:15,715 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:36:16,006 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:36:16,006 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:36:16,006 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:36:16,123 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:36:17,673 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:36:17,673 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:43:38,154 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:43:38,433 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:43:38,788 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:44:22,133 - WARNING - Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:44:22,265 - WARNING - Cannot set gray stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:44:22,431 - WARNING - Cannot set gray stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:52:10,840 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:52:10,890 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:52:10,957 - WARNING - Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:52:11,059 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:52:11,090 - WARNING - Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:52:11,090 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:52:11,144 - WARNING - Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
      "2025-09-25 16:52:11,206 - WARNING - Cannot set gray non-stroke color because /'P6' is an invalid float value\n",
      "2025-09-25 16:52:11,320 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:52:11,340 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:52:11,390 - WARNING - Cannot set gray non-stroke color because /'P7' is an invalid float value\n",
      "2025-09-25 16:52:11,706 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:52:12,073 - WARNING - Cannot set gray non-stroke color because /'P9' is an invalid float value\n",
      "2025-09-25 16:52:12,125 - WARNING - Cannot set gray non-stroke color because /'P10' is an invalid float value\n",
      "2025-09-25 16:52:12,174 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:52:12,192 - WARNING - Cannot set gray non-stroke color because /'P11' is an invalid float value\n",
      "2025-09-25 16:52:12,233 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:52:53,207 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:52:53,242 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:52:53,291 - WARNING - Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:52:53,368 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:52:53,390 - WARNING - Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:52:53,390 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:52:53,431 - WARNING - Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
      "2025-09-25 16:52:53,466 - WARNING - Cannot set gray non-stroke color because /'P6' is an invalid float value\n",
      "2025-09-25 16:52:53,525 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 16:52:53,540 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:52:53,558 - WARNING - Cannot set gray non-stroke color because /'P7' is an invalid float value\n",
      "2025-09-25 16:52:53,758 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:52:53,942 - WARNING - Cannot set gray non-stroke color because /'P9' is an invalid float value\n",
      "2025-09-25 16:52:53,979 - WARNING - Cannot set gray non-stroke color because /'P10' is an invalid float value\n",
      "2025-09-25 16:52:54,007 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:52:54,039 - WARNING - Cannot set gray non-stroke color because /'P11' is an invalid float value\n",
      "2025-09-25 16:52:54,057 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:52:55,975 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:52:56,024 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:52:56,076 - WARNING - Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "2025-09-25 16:52:56,139 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:52:56,167 - WARNING - Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "2025-09-25 16:52:56,172 - WARNING - Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "2025-09-25 16:52:56,201 - WARNING - Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
      "2025-09-25 16:52:56,251 - WARNING - Cannot set gray non-stroke color because /'P6' is an invalid float value\n",
      "2025-09-25 16:52:56,308 - WARNING - Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "2025-09-25 16:52:56,325 - WARNING - Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "2025-09-25 16:52:56,362 - WARNING - Cannot set gray non-stroke color because /'P7' is an invalid float value\n",
      "2025-09-25 16:52:56,592 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:52:56,783 - WARNING - Cannot set gray non-stroke color because /'P9' is an invalid float value\n",
      "2025-09-25 16:52:56,823 - WARNING - Cannot set gray non-stroke color because /'P10' is an invalid float value\n",
      "2025-09-25 16:52:56,861 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "2025-09-25 16:52:56,869 - WARNING - Cannot set gray non-stroke color because /'P11' is an invalid float value\n",
      "2025-09-25 16:52:56,893 - WARNING - Cannot set gray non-stroke color because /'P8' is an invalid float value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>company_name</th>\n",
       "      <th>report_title</th>\n",
       "      <th>financial_year</th>\n",
       "      <th>assurance_provider</th>\n",
       "      <th>assurance_type</th>\n",
       "      <th>plants_india</th>\n",
       "      <th>offices_india</th>\n",
       "      <th>plants_outside_india</th>\n",
       "      <th>offices_outside_india</th>\n",
       "      <th>exports_pct_standalone</th>\n",
       "      <th>employees_total_consolidated</th>\n",
       "      <th>employees_perm_consolidated</th>\n",
       "      <th>workers_perm_consolidated</th>\n",
       "      <th>complaints_posh_total_standalone</th>\n",
       "      <th>standards_referenced</th>\n",
       "      <th>policies_weblink</th>\n",
       "      <th>material_issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSE_PAG_2024_business_esg.pdf</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CDP, TCFD</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung_Electronics_Sustainability_Report_2025...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CDP, GRI, SASB, TCFD</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acer-incorporated_2023.pdf</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CDP, GRI, SASB, TCFD</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deutsche_esg.pdf</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0 0 8 32 40</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CDP, GRI, TCFD</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intel_esg.pdf</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CDP, GRI, SASB, TCFD</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nippon_esg.pdf</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>GRI, TCFD</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tata_steel_esg.pdf</td>\n",
       "      <td>Tata Steel Limited</td>\n",
       "      <td>Business Responsibility And Sustainability Report</td>\n",
       "      <td>2024-25</td>\n",
       "      <td>assurance on BRSR Core indicators and select i...</td>\n",
       "      <td>PW &amp; Co CA LLP has undertaken reasonable assur...</td>\n",
       "      <td>76</td>\n",
       "      <td>143</td>\n",
       "      <td>39</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>75</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2014</td>\n",
       "      <td>ResponsibleSteel, TCFD</td>\n",
       "      <td></td>\n",
       "      <td>Greenhouse Gas Emissions and Climate Change Ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file        company_name  \\\n",
       "0                      LSE_PAG_2024_business_esg.pdf                       \n",
       "1  Samsung_Electronics_Sustainability_Report_2025...                       \n",
       "2                         acer-incorporated_2023.pdf                       \n",
       "3                                   deutsche_esg.pdf                       \n",
       "4                                      intel_esg.pdf                       \n",
       "5                                     nippon_esg.pdf                       \n",
       "6                                 tata_steel_esg.pdf  Tata Steel Limited   \n",
       "\n",
       "                                        report_title financial_year  \\\n",
       "0                                                                     \n",
       "1                                                                     \n",
       "2                                                                     \n",
       "3                                                       0 0 8 32 40   \n",
       "4                                                                     \n",
       "5                                                                     \n",
       "6  Business Responsibility And Sustainability Report        2024-25   \n",
       "\n",
       "                                  assurance_provider  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "5                                                      \n",
       "6  assurance on BRSR Core indicators and select i...   \n",
       "\n",
       "                                      assurance_type plants_india  \\\n",
       "0                                                                   \n",
       "1                                                                   \n",
       "2                                                                   \n",
       "3                                                                   \n",
       "4                                                                   \n",
       "5                                                                   \n",
       "6  PW & Co CA LLP has undertaken reasonable assur...           76   \n",
       "\n",
       "  offices_india plants_outside_india offices_outside_india  \\\n",
       "0                                                            \n",
       "1                                                            \n",
       "2                                                            \n",
       "3                                                            \n",
       "4                                                            \n",
       "5                                                            \n",
       "6           143                   39                    20   \n",
       "\n",
       "  exports_pct_standalone employees_total_consolidated  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4                                                       \n",
       "5                                                       \n",
       "6                      6                           75   \n",
       "\n",
       "  employees_perm_consolidated workers_perm_consolidated  \\\n",
       "0                                                         \n",
       "1                                                         \n",
       "2                                                         \n",
       "3                                                         \n",
       "4                                                         \n",
       "5                                                         \n",
       "6                                                         \n",
       "\n",
       "  complaints_posh_total_standalone    standards_referenced policies_weblink  \\\n",
       "0                                                CDP, TCFD                    \n",
       "1                                     CDP, GRI, SASB, TCFD                    \n",
       "2                                     CDP, GRI, SASB, TCFD                    \n",
       "3                                           CDP, GRI, TCFD                    \n",
       "4                                     CDP, GRI, SASB, TCFD                    \n",
       "5                                                GRI, TCFD                    \n",
       "6                             2014  ResponsibleSteel, TCFD                    \n",
       "\n",
       "                                     material_issues  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2                                                     \n",
       "3                                                     \n",
       "4                                                     \n",
       "5                                                     \n",
       "6  Greenhouse Gas Emissions and Climate Change Ma...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: B:\\mandg\\ESG_Deliverables\\ESG_Deliverables_with_Summary\\outputs\\brsr_metadata.json B:\\mandg\\ESG_Deliverables\\ESG_Deliverables_with_Summary\\outputs\\brsr_metadata_1.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, re, json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "import pandas as pd\n",
    "\n",
    "PDFS_DIR = r\"B:\\mandg\\ESG_Deliverables\\ESG_Deliverables_with_Summary\\data\"\n",
    "OUT_DIR  = r\"B:\\mandg\\ESG_Deliverables\\ESG_Deliverables_with_Summary\\outputs\"\n",
    "\n",
    "try:\n",
    "    read_pdf_text\n",
    "except NameError:\n",
    "    try:\n",
    "        import PyPDF2\n",
    "        def read_pdf_text(pdf_path: str):\n",
    "            pages = []\n",
    "            with open(pdf_path, \"rb\") as f:\n",
    "                reader = PyPDF2.PdfReader(f)\n",
    "                for i, page in enumerate(reader.pages):\n",
    "                    try:\n",
    "                        raw = page.extract_text() or \"\"\n",
    "                    except Exception:\n",
    "                        raw = \"\"\n",
    "                    pages.append({\"page\": i+1, \"text\": raw})\n",
    "            return pages\n",
    "    except Exception:\n",
    "        def read_pdf_text(pdf_path: str): return []\n",
    "\n",
    "def _join(pages: List[Dict[str, Any]]) -> str:\n",
    "    return \"\\n\\n\".join([p.get(\"text\",\"\") for p in pages])\n",
    "\n",
    "def _search(pattern, text, flags=re.IGNORECASE|re.MULTILINE|re.DOTALL, group=1, default=\"\"):\n",
    "    m = re.search(pattern, text, flags)\n",
    "    if not m: return default\n",
    "    try:\n",
    "        return m.group(group).strip()\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def extract_brsr_structured(pdf_path: str) -> Dict[str, Any]:\n",
    "    pages = read_pdf_text(pdf_path)\n",
    "    txt = _join(pages)\n",
    "\n",
    "    data: Dict[str, Any] = {\n",
    "        \"file\": os.path.basename(pdf_path),\n",
    "        \"company_name\": \"\",\n",
    "        \"report_title\": \"\",\n",
    "        \"financial_year\": \"\",\n",
    "        \"assurance_provider\": \"\",\n",
    "        \"assurance_type\": \"\",\n",
    "        \"plants_india\": \"\",\n",
    "        \"offices_india\": \"\",\n",
    "        \"plants_outside_india\": \"\",\n",
    "        \"offices_outside_india\": \"\",\n",
    "        \"exports_pct_standalone\": \"\",\n",
    "        \"employees_total_consolidated\": \"\",\n",
    "        \"employees_perm_consolidated\": \"\",\n",
    "        \"workers_perm_consolidated\": \"\",\n",
    "        \"complaints_posh_total_standalone\": \"\",\n",
    "        \"standards_referenced\": [],\n",
    "        \"material_issues\": [],\n",
    "        \"policies_weblink\": \"\"\n",
    "    }\n",
    "\n",
    "    data[\"report_title\"] = _search(r\"(?i)(BUSINESS RESPONSIBILITY AND SUSTAINABILITY REPORT)\", txt, group=1, default=\"\").title()\n",
    "    data[\"financial_year\"] = _search(r\"(?i)Financial Year\\s+([0-9\\-–/ ]{7,})\", txt, group=1, default=\"\")\n",
    "    data[\"company_name\"] = _search(r\"(?i)\\bName of the Listed Entity\\s+([^\\n]+)\", txt)\n",
    "\n",
    "    data[\"assurance_provider\"] = _search(r\"(?i)Name of Assurance Provider\\s+.*?\\n(.+?)\\n\", txt)\n",
    "    data[\"assurance_type\"] = _search(r\"(?i)Type of Assurance Obtained\\s+(.+?)\\n\", txt)\n",
    "\n",
    "    data[\"policies_weblink\"] = _search(r\"(?i)Web-Link of the\\s+Policies.*?Link:\\s*(https?://\\S+)\", txt)\n",
    "\n",
    "    plants_block = _search(r\"(?i)Number of locations where plants.*?\\n+Location.*?\\n+(.*?)(?:\\n{2,}|\\Z)\", txt, group=1, default=\"\")\n",
    "    if plants_block:\n",
    "        def _get_num(label):\n",
    "            m = re.search(rf\"{label}\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\", plants_block, re.IGNORECASE)\n",
    "            return m.groups() if m else (\"\",\"\",\"\")\n",
    "        ind = _get_num(\"India\")\n",
    "        out = _get_num(\"Outside India\")\n",
    "        if ind != (\"\",\"\",\"\"):\n",
    "            data[\"plants_india\"], data[\"offices_india\"], _total = ind\n",
    "        if out != (\"\",\"\",\"\"):\n",
    "            data[\"plants_outside_india\"], data[\"offices_outside_india\"], _tot2 = out\n",
    "\n",
    "    data[\"exports_pct_standalone\"] = _search(r\"(?i)% of exports in total revenue\\s+(\\d+)\\s\", txt)\n",
    "\n",
    "    data[\"employees_perm_consolidated\"] = _search(r\"(?i)Permanent\\s*\\(E\\)\\s+(\\d{2,})\\s\", txt)\n",
    "    data[\"workers_perm_consolidated\"] = _search(r\"(?i)Workers.*?Permanent\\s*\\(G\\)\\s+(\\d{2,})\\s\", txt)\n",
    "    data[\"employees_total_consolidated\"] = _search(r\"(?i)Total Employees\\s*\\(E\\+\\s*F\\)\\s+(\\d{2,})\", txt)\n",
    "\n",
    "    data[\"complaints_posh_total_standalone\"] = _search(r\"(?i)Total Complaints reported.*?Standalone.*?\\n.*?\\n.*?\\n.*?\\n.*?\\n?(\\d+)\\s\", txt)\n",
    "\n",
    "    std_hits = set()\n",
    "    for tag in [\"SASB\", \"GRI\", \"TCFD\", \"CDP\", \"UNGC\", \"ResponsibleSteel\"]:\n",
    "        if re.search(rf\"\\b{tag}\\b\", txt, re.IGNORECASE):\n",
    "            std_hits.add(tag)\n",
    "    data[\"standards_referenced\"] = sorted(std_hits)\n",
    "\n",
    "    mat_block = _search(r\"(?i)Material issues identified(.*?)(?:SECTION B|Governance, Leadership)\", txt, group=1, default=\"\")\n",
    "    if not mat_block:\n",
    "        mat_block = _search(r\"(?i)Material issues.*?(A\\.\\s*STRATEGIC.*?)(?:\\n\\d+\\.\\s|SECTION B)\", txt, group=1, default=\"\")\n",
    "    issues = []\n",
    "    for m in re.finditer(r\"(?m)^[ABC]\\d+\\.\\s+([^\\n]+)\", mat_block):\n",
    "        issues.append(m.group(1).strip())\n",
    "    data[\"material_issues\"] = issues[:12]\n",
    "\n",
    "    return data\n",
    "\n",
    "def run_brsr_batch(pdf_dir=PDFS_DIR):\n",
    "    pdfs = sorted([str(p) for p in Path(pdf_dir).glob(\"*.pdf\")])\n",
    "    results = [extract_brsr_structured(p) for p in pdfs]\n",
    "    out_json = Path(OUT_DIR) / \"brsr_metadata.json\"\n",
    "    out_json.write_text(json.dumps(results, indent=2))\n",
    "    rows = []\n",
    "    for d in results:\n",
    "        row = {k: (\", \".join(v) if isinstance(v, list) else v) for k, v in d.items() if k != \"material_issues\"}\n",
    "        row[\"material_issues\"] = \"; \".join(d.get(\"material_issues\", []))\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    out_csv = Path(OUT_DIR) / \"brsr_metadata_1.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    display(df.head(20))\n",
    "    print(\"Wrote:\", out_json, out_csv)\n",
    "    return df\n",
    "\n",
    "df_brsr = run_brsr_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aef505fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Post-processing & Global Summarization for ESG Claim Analysis\n",
    "\n",
    "This module expects a DataFrame with at least the following columns:\n",
    "- Company (str)\n",
    "- Sector (str)\n",
    "- ESG Topic (str)\n",
    "- Extracted Claim (str)\n",
    "- Sentiment Score (float, -1..1 or 0..1)\n",
    "- Specificity Score (float, 0..1)\n",
    "- Greenwashing Risk Score (Optional) (float, 0..1)\n",
    "\n",
    "Outputs:\n",
    "- outputs/cross_company_summary.csv\n",
    "- outputs/executive_summary.md\n",
    "- outputs/topic_briefs.md\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Dict\n",
    "\n",
    "def _safe_mean(series):\n",
    "    s = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
    "    return float(s.mean()) if len(s) else float(\"nan\")\n",
    "\n",
    "def _normalize_topic(t: str) -> str:\n",
    "    if not isinstance(t, str):\n",
    "        return \"Unknown\"\n",
    "    return re.sub(r\"\\s+\", \" \", t.strip()).title()\n",
    "\n",
    "def _top_n_strings(strings: List[str], n=5, min_len=30):\n",
    "    seen = set()\n",
    "    uniq = []\n",
    "    for s in strings:\n",
    "        if not isinstance(s, str):\n",
    "            continue\n",
    "        s_clean = s.strip()\n",
    "        if len(s_clean) < min_len:\n",
    "            continue\n",
    "        if s_clean in seen:\n",
    "            continue\n",
    "        seen.add(s_clean)\n",
    "        uniq.append(s_clean)\n",
    "    return uniq[:n]\n",
    "\n",
    "def aggregate(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute cross-company aggregates by ESG Topic and Sector.\"\"\"\n",
    "    if \"ESG Topic\" not in df.columns:\n",
    "        raise ValueError(\"Expected 'ESG Topic' column in DataFrame\")\n",
    "    tmp = df.copy()\n",
    "    tmp[\"ESG Topic\"] = tmp[\"ESG Topic\"].map(_normalize_topic)\n",
    "\n",
    "    group_cols = [\"ESG Topic\", \"Sector\"]\n",
    "    agg = tmp.groupby(group_cols).agg(\n",
    "        num_claims=(\"Extracted Claim\", \"count\"),\n",
    "        num_companies=(\"Company\", lambda s: s.nunique()),\n",
    "        avg_sentiment=(\"Sentiment Score\", _safe_mean),\n",
    "        avg_specificity=(\"Specificity Score\", _safe_mean),\n",
    "        avg_greenwash=(\"Greenwashing Risk Score (Optional)\", _safe_mean) if \"Greenwashing Risk Score (Optional)\" in tmp.columns else (\"Sentiment Score\", lambda s: float(\"nan\")),\n",
    "    ).reset_index()\n",
    "\n",
    "    # topic coverage (#companies per topic)\n",
    "    coverage = tmp.groupby(\"ESG Topic\")[\"Company\"].nunique().rename(\"companies_per_topic\").reset_index()\n",
    "\n",
    "    # save aggregates\n",
    "    out_path = os.path.join(\"outputs\", \"cross_company_summary.csv\")\n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    agg.to_csv(out_path, index=False)\n",
    "    return agg.merge(coverage, on=\"ESG Topic\", how=\"left\")\n",
    "\n",
    "def _quantize(series, q=(0.25, 0.75)):\n",
    "    s = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
    "    if len(s) < 3:\n",
    "        return (None, None)\n",
    "    return (float(s.quantile(q[0])), float(s.quantile(q[1])))\n",
    "\n",
    "def _mk_bullets(items: List[str]) -> str:\n",
    "    return \"\".join([f\"- {it}\\n\" for it in items])\n",
    "\n",
    "def _summarize_findings(agg: pd.DataFrame, df: pd.DataFrame) -> str:\n",
    "    \"\"\"Create a compact executive narrative with data-backed highlights.\"\"\"\n",
    "    low_q, high_q = _quantize(agg[\"avg_specificity\"])\n",
    "    low_s, high_s = _quantize(agg[\"avg_sentiment\"])\n",
    "\n",
    "    strengths = agg.sort_values([\"avg_specificity\",\"avg_sentiment\"], ascending=[False, False])\\\n",
    "                   .head(5)[\"ESG Topic\"].tolist()\n",
    "    risks = agg.sort_values([\"avg_specificity\",\"avg_sentiment\"], ascending=[True, True])\\\n",
    "               .head(5)[\"ESG Topic\"].tolist()\n",
    "\n",
    "    # Topic breadth\n",
    "    topic_breadth = agg[[\"ESG Topic\",\"companies_per_topic\"]]\\\n",
    "        .sort_values(\"companies_per_topic\", ascending=False).head(5)\n",
    "    breadth_lines = [f\"{r['ESG Topic']} ({int(r['companies_per_topic'])} companies)\"\n",
    "                     for _, r in topic_breadth.iterrows()]\n",
    "\n",
    "    # Claim exemplars: pick a few representative claims with high specificity and polarity extremes\n",
    "    pos_examples = df.sort_values(\"Sentiment Score\", ascending=False)\\\n",
    "                     .dropna(subset=[\"Extracted Claim\"])\\\n",
    "                     .groupby(\"ESG Topic\")[\"Extracted Claim\"].apply(lambda s: _top_n_strings(list(s), n=1))\\\n",
    "                     .explode().dropna().head(5).tolist()\n",
    "\n",
    "    neg_examples = df.sort_values(\"Sentiment Score\", ascending=True)\\\n",
    "                     .dropna(subset=[\"Extracted Claim\"])\\\n",
    "                     .groupby(\"ESG Topic\")[\"Extracted Claim\"].apply(lambda s: _top_n_strings(list(s), n=1))\\\n",
    "                     .explode().dropna().head(5).tolist()\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"## Executive Summary\")\n",
    "    lines.append(\"This section synthesizes all parsed PDFs to highlight cross-company patterns and notable claims.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"### Where companies look strongest (high specificity & positive sentiment)\")\n",
    "    lines.append(_mk_bullets(strengths) if strengths else \"- (insufficient data)\\n\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"### Potential risk/greenwashing hotspots (low specificity & positive tone or ambiguity)\")\n",
    "    lines.append(_mk_bullets(risks) if risks else \"- (insufficient data)\\n\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"### Most commonly covered topics (by # of companies)\")\n",
    "    lines.append(_mk_bullets(breadth_lines) if breadth_lines else \"- (insufficient data)\\n\")\n",
    "    lines.append(\"\")\n",
    "    if pos_examples:\n",
    "        lines.append(\"### Representative positive claims\")\n",
    "        lines.append(_mk_bullets(pos_examples))\n",
    "        lines.append(\"\")\n",
    "    if neg_examples:\n",
    "        lines.append(\"### Representative challenges/risks\")\n",
    "        lines.append(_mk_bullets(neg_examples))\n",
    "        lines.append(\"\")\n",
    "\n",
    "    return \"\\n\".join(lines).strip() + \"\\n\"\n",
    "\n",
    "def _topic_briefs(agg: pd.DataFrame) -> str:\n",
    "    \"\"\"Create concise briefs per topic with directional guidance.\"\"\"\n",
    "    lines = [\"# Topic Briefs\", \"\"]\n",
    "    for _, r in agg.sort_values(\"ESG Topic\").iterrows():\n",
    "        topic = r[\"ESG Topic\"]\n",
    "        lines.append(f\"## {topic}\")\n",
    "        lines.append(f\"- Companies covering: **{int(r['companies_per_topic']) if not pd.isna(r['companies_per_topic']) else 0}**\")\n",
    "        lines.append(f\"- Avg. Sentiment: **{r['avg_sentiment']:.2f}** | Avg. Specificity: **{r['avg_specificity']:.2f}**\")\n",
    "        if not pd.isna(r.get(\"avg_greenwash\", float('nan'))):\n",
    "            try:\n",
    "                lines.append(f\"- Avg. Greenwashing Risk (opt): **{r['avg_greenwash']:.2f}**\")\n",
    "            except Exception:\n",
    "                pass\n",
    "        lines.append(\"\")\n",
    "    return \"\\n\".join(lines).strip() + \"\\n\"\n",
    "\n",
    "def run_global_summary(input_csv: str, output_dir: str = \"outputs\") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Execute full post-processing:\n",
    "    1) Load the per-claim CSV\n",
    "    2) Aggregate across companies\n",
    "    3) Write cross_company_summary.csv, executive_summary.md, topic_briefs.md\n",
    "    Returns dict of generated paths.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    df = pd.read_csv(input_csv)\n",
    "    agg = aggregate(df)\n",
    "    agg_path = os.path.join(output_dir, \"cross_company_summary.csv\")\n",
    "    agg.to_csv(agg_path, index=False)\n",
    "\n",
    "    exec_md = _summarize_findings(agg, df)\n",
    "    exec_path = os.path.join(output_dir, \"executive_summary.md\")\n",
    "    with open(exec_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(exec_md)\n",
    "\n",
    "    briefs_md = _topic_briefs(agg)\n",
    "    briefs_path = os.path.join(output_dir, \"topic_briefs.md\")\n",
    "    with open(briefs_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(briefs_md)\n",
    "\n",
    "    return {\"aggregates\": agg_path, \"executive_summary\": exec_path, \"topic_briefs\": briefs_path}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "878137e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Company-Centric Post-processing & Global Summarization for ESG Claim Analysis\n",
    "\n",
    "Expected input CSV columns (minimum):\n",
    "- Company (str)\n",
    "- Sector (str)\n",
    "- ESG Topic (str)\n",
    "- Extracted Claim (str)\n",
    "- Sentiment Score (float, -1..1 or 0..1)\n",
    "- Specificity Score (float, 0..1)\n",
    "- Greenwashing Risk Score (Optional) (float, 0..1)\n",
    "\n",
    "Primary outputs (company-focused):\n",
    "- outputs/company_summary.csv\n",
    "- outputs/company_executive_summary.md\n",
    "- outputs/company_briefs.md\n",
    "\n",
    "Backward-compatibility aliases (same content as above):\n",
    "- outputs/cross_company_summary.csv       -> company_summary.csv\n",
    "- outputs/executive_summary.md            -> company_executive_summary.md\n",
    "- outputs/topic_briefs.md                 -> company_briefs.md\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import re\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ---------------------- Helpers ----------------------\n",
    "\n",
    "def _safe_mean(series) -> float:\n",
    "    s = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
    "    return float(s.mean()) if len(s) else float(\"nan\")\n",
    "\n",
    "\n",
    "def _top_n_strings(strings: List[str], n: int = 3, min_len: int = 30) -> List[str]:\n",
    "    \"\"\"Pick up to n unique, reasonably long strings (claims).\"\"\"\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for s in strings:\n",
    "        if not isinstance(s, str):\n",
    "            continue\n",
    "        s = s.strip()\n",
    "        if len(s) < min_len:\n",
    "            continue\n",
    "        if s in seen:\n",
    "            continue\n",
    "        seen.add(s)\n",
    "        out.append(s)\n",
    "        if len(out) >= n:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "\n",
    "def _mk_bullets(items: List[str]) -> str:\n",
    "    if not items:\n",
    "        return \"- (insufficient data)\\n\"\n",
    "    return \"\".join([f\"- {it}\\n\" for it in items])\n",
    "\n",
    "\n",
    "def _fmt_float(v) -> str:\n",
    "    try:\n",
    "        if pd.isna(v):\n",
    "            return \"na\"\n",
    "        return f\"{float(v):.2f}\"\n",
    "    except Exception:\n",
    "        return \"na\"\n",
    "\n",
    "\n",
    "# ---------------------- Aggregations ----------------------\n",
    "\n",
    "def aggregate_by_company(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Aggregate metrics at the Company level (with Sector included).\"\"\"\n",
    "    if \"Company\" not in df.columns:\n",
    "        raise ValueError(\"Expected 'Company' column in DataFrame\")\n",
    "\n",
    "    if \"Sector\" not in df.columns:\n",
    "        df = df.copy()\n",
    "        df[\"Sector\"] = \"Unknown\"\n",
    "\n",
    "    # Base aggregations\n",
    "    agg = df.groupby([\"Company\", \"Sector\"]).agg(\n",
    "        num_claims=(\"Extracted Claim\", \"count\"),\n",
    "        avg_sentiment=(\"Sentiment Score\", _safe_mean),\n",
    "        avg_specificity=(\"Specificity Score\", _safe_mean),\n",
    "    ).reset_index()\n",
    "\n",
    "    # Optional greenwashing risk, if present\n",
    "    if \"Greenwashing Risk Score\" in df.columns:\n",
    "        gw = (\n",
    "            df.groupby([\"Company\", \"Sector\"])[\"Greenwashing Risk Score\"]\n",
    "              .apply(_safe_mean)\n",
    "              .reset_index(name=\"avg_greenwash\")\n",
    "        )\n",
    "        agg = agg.merge(gw, on=[\"Company\", \"Sector\"], how=\"left\")\n",
    "    else:\n",
    "        agg[\"avg_greenwash\"] = float(\"nan\")\n",
    "\n",
    "    # Topics covered per company\n",
    "    topics_per_company = (\n",
    "        df.groupby(\"Company\")[\"ESG Topic\"]\n",
    "          .nunique()\n",
    "          .rename(\"num_topics\")\n",
    "          .reset_index()\n",
    "    )\n",
    "    agg = agg.merge(topics_per_company, on=\"Company\", how=\"left\")\n",
    "\n",
    "    # Ensure integer-like columns are ints where possible\n",
    "    for col in (\"num_claims\", \"num_topics\"):\n",
    "        if col in agg.columns:\n",
    "            agg[col] = pd.to_numeric(agg[col], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "    return agg\n",
    "\n",
    "\n",
    "def top_topics_per_company(df: pd.DataFrame, n: int = 3) -> Dict[str, List[str]]:\n",
    "    \"\"\"Return top-N topics by frequency for each company.\"\"\"\n",
    "    out: Dict[str, List[str]] = {}\n",
    "    if \"ESG Topic\" not in df.columns:\n",
    "        return out\n",
    "    norm = df.copy()\n",
    "    norm[\"ESG Topic\"] = (\n",
    "        norm[\"ESG Topic\"].astype(str).str.strip().str.replace(r\"\\s+\", \" \", regex=True).str.title()\n",
    "    )\n",
    "    for company, sub in norm.groupby(\"Company\"):\n",
    "        counts = sub[\"ESG Topic\"].value_counts()\n",
    "        out[company] = counts.head(n).index.tolist()\n",
    "    return out\n",
    "\n",
    "\n",
    "def representative_claims(df: pd.DataFrame, n: int = 1) -> Tuple[Dict[str, List[str]], Dict[str, List[str]]]:\n",
    "    \"\"\"Return top positive and top negative claims per company.\"\"\"\n",
    "    pos: Dict[str, List[str]] = {}\n",
    "    neg: Dict[str, List[str]] = {}\n",
    "    for company, sub in df.groupby(\"Company\"):\n",
    "        sub = sub.dropna(subset=[\"Extracted Claim\"])\n",
    "        # If sentiment is missing, skip ordering\n",
    "        if \"Sentiment Score\" in sub.columns:\n",
    "            sub_pos = sub.sort_values(\"Sentiment Score\", ascending=False)\n",
    "            sub_neg = sub.sort_values(\"Sentiment Score\", ascending=True)\n",
    "        else:\n",
    "            sub_pos = sub\n",
    "            sub_neg = sub\n",
    "        pos[company] = _top_n_strings(sub_pos[\"Extracted Claim\"].tolist(), n=n)\n",
    "        neg[company] = _top_n_strings(sub_neg[\"Extracted Claim\"].tolist(), n=n)\n",
    "    return pos, neg\n",
    "\n",
    "\n",
    "# ---------------------- Narratives ----------------------\n",
    "\n",
    "def company_executive_summary(\n",
    "    agg: pd.DataFrame,\n",
    "    top_topics: Dict[str, List[str]],\n",
    "    pos: Dict[str, List[str]],\n",
    "    neg: Dict[str, List[str]],\n",
    ") -> str:\n",
    "    \"\"\"Construct a company-centric executive summary markdown.\"\"\"\n",
    "    lines = []\n",
    "    lines.append(\"## Executive Summary (Company-Centric)\")\n",
    "    lines.append(\"This summary consolidates all analyzed PDFs and highlights company-level patterns and notable claims.\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    if not agg.empty:\n",
    "        leaders = agg.sort_values(\n",
    "            [\"avg_specificity\", \"avg_sentiment\"],\n",
    "            ascending=[False, False]\n",
    "        ).head(5)\n",
    "\n",
    "        laggards = agg.sort_values(\n",
    "            [\"avg_specificity\", \"avg_sentiment\"],\n",
    "            ascending=[True, True]\n",
    "        ).head(5)\n",
    "\n",
    "        lines.append(\"### Leaders (higher specificity & positive sentiment)\")\n",
    "        if len(leaders):\n",
    "            for _, r in leaders.iterrows():\n",
    "                lines.append(\n",
    "                    f\"- {r.Company} ({r.Sector}): \"\n",
    "                    f\"claims={int(r.num_claims)}, topics={int(r.num_topics)}, \"\n",
    "                    f\"avg_sent={_fmt_float(r.avg_sentiment)}, \"\n",
    "                    f\"avg_spec={_fmt_float(r.avg_specificity)}\"\n",
    "                )\n",
    "        else:\n",
    "            lines.append(\"- (insufficient data)\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "        lines.append(\"### Potential risk/greenwashing hotspots (lower specificity & positive tone or ambiguity)\")\n",
    "        if len(laggards):\n",
    "            for _, r in laggards.iterrows():\n",
    "                lines.append(\n",
    "                    f\"- {r.Company} ({r.Sector}): \"\n",
    "                    f\"claims={int(r.num_claims)}, topics={int(r.num_topics)}, \"\n",
    "                    f\"avg_sent={_fmt_float(r.avg_sentiment)}, \"\n",
    "                    f\"avg_spec={_fmt_float(r.avg_specificity)}\"\n",
    "                )\n",
    "        else:\n",
    "            lines.append(\"- (insufficient data)\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "    lines.append(\"### Coverage overview (top topics per company)\")\n",
    "    companies = sorted(top_topics.keys())\n",
    "    if companies:\n",
    "        for company in companies:\n",
    "            topics = \", \".join(top_topics.get(company, [])[:3]) or \"—\"\n",
    "            lines.append(f\"- **{company}**: {topics}\")\n",
    "    else:\n",
    "        lines.append(\"- (insufficient data)\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    lines.append(\"### Representative claims by company\")\n",
    "    for company in sorted(set(list(pos.keys()) + list(neg.keys()))):\n",
    "        lines.append(f\"- **{company}**\")\n",
    "        p = pos.get(company, [])\n",
    "        n = neg.get(company, [])\n",
    "        if p:\n",
    "            lines.append(f\"  - Positive: {p[0]}\")\n",
    "        if n:\n",
    "            lines.append(f\"  - Challenge/Risk: {n[0]}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    return \"\\n\".join(lines).strip() + \"\\n\"\n",
    "\n",
    "\n",
    "def company_briefs_md(\n",
    "    agg: pd.DataFrame,\n",
    "    top_topics: Dict[str, List[str]],\n",
    "    pos: Dict[str, List[str]],\n",
    "    neg: Dict[str, List[str]],\n",
    ") -> str:\n",
    "    \"\"\"Per-company briefs with directional metrics.\"\"\"\n",
    "    lines = [\"# Company Briefs\", \"\"]\n",
    "    if agg.empty:\n",
    "        lines.append(\"_No data available._\\n\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    for _, r in agg.sort_values([\"Sector\", \"Company\"]).iterrows():\n",
    "        company = r[\"Company\"]\n",
    "        lines.append(f\"## {company}\")\n",
    "        lines.append(f\"- Sector: **{r['Sector']}**\")\n",
    "        lines.append(f\"- Claims: **{int(r['num_claims'])}**, Topics: **{int(r['num_topics'])}**\")\n",
    "        lines.append(f\"- Avg. Sentiment: **{_fmt_float(r['avg_sentiment'])}**, Avg. Specificity: **{_fmt_float(r['avg_specificity'])}**\")\n",
    "        if \"avg_greenwash\" in agg.columns:\n",
    "            lines.append(f\"- Avg. Greenwashing Risk (opt): **{_fmt_float(r.get('avg_greenwash'))}**\")\n",
    "        tt = \", \".join(top_topics.get(company, [])[:3]) or \"—\"\n",
    "        lines.append(f\"- Top topics: {tt}\")\n",
    "        pc = pos.get(company, [])\n",
    "        nc = neg.get(company, [])\n",
    "        if pc:\n",
    "            lines.append(f\"- Representative positive claim: {pc[0]}\")\n",
    "        if nc:\n",
    "            lines.append(f\"- Representative challenge/risk: {nc[0]}\")\n",
    "        lines.append(\"\")\n",
    "    return \"\\n\".join(lines).strip() + \"\\n\"\n",
    "\n",
    "\n",
    "# ---------------------- Public Entry Point ----------------------\n",
    "\n",
    "def run_global_summary(input_csv: str, output_dir: str = \"outputs\"):\n",
    "    \"\"\"\n",
    "    Company-centric post-processing:\n",
    "    1) Load the per-claim CSV\n",
    "    2) Aggregate metrics by company\n",
    "    3) Produce: company_summary.csv, company_executive_summary.md, company_briefs.md\n",
    "    Also writes backward-compatible aliases.\n",
    "    Returns dict of generated paths.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    agg = aggregate_by_company(df)\n",
    "    top_topics = top_topics_per_company(df, n=3)\n",
    "    pos, neg = representative_claims(df, n=1)\n",
    "\n",
    "    # Primary outputs\n",
    "    company_summary_path = os.path.join(output_dir, \"company_summary.csv\")\n",
    "    agg.to_csv(company_summary_path, index=False)\n",
    "\n",
    "    exec_md = company_executive_summary(agg, top_topics, pos, neg)\n",
    "    company_exec_path = os.path.join(output_dir, \"company_executive_summary.md\")\n",
    "    with open(company_exec_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(exec_md)\n",
    "\n",
    "    briefs_md = company_briefs_md(agg, top_topics, pos, neg)\n",
    "    company_briefs_path = os.path.join(output_dir, \"company_briefs.md\")\n",
    "    with open(company_briefs_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(briefs_md)\n",
    "\n",
    "    # Backward-compatibility aliases\n",
    "    cross_company_summary_path = os.path.join(output_dir, \"cross_company_summary.csv\")\n",
    "    agg.to_csv(cross_company_summary_path, index=False)\n",
    "\n",
    "    exec_compat_path = os.path.join(output_dir, \"executive_summary.md\")\n",
    "    with open(exec_compat_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(exec_md)\n",
    "\n",
    "    topic_briefs_compat_path = os.path.join(output_dir, \"topic_briefs.md\")\n",
    "    with open(topic_briefs_compat_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(briefs_md)\n",
    "\n",
    "    return {\n",
    "        \"company_summary\": company_summary_path,\n",
    "        \"company_executive_summary\": company_exec_path,\n",
    "        \"company_briefs\": company_briefs_path,\n",
    "        \"cross_company_summary (compat)\": cross_company_summary_path,\n",
    "        \"executive_summary (compat)\": exec_compat_path,\n",
    "        \"topic_briefs (compat)\": topic_briefs_compat_path,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1675d048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company_summary': 'B:\\\\mandg\\\\ESG_Deliverables\\\\ESG_Deliverables_with_Summary\\\\outputs\\\\company_summary.csv',\n",
       " 'company_executive_summary': 'B:\\\\mandg\\\\ESG_Deliverables\\\\ESG_Deliverables_with_Summary\\\\outputs\\\\company_executive_summary.md',\n",
       " 'company_briefs': 'B:\\\\mandg\\\\ESG_Deliverables\\\\ESG_Deliverables_with_Summary\\\\outputs\\\\company_briefs.md',\n",
       " 'cross_company_summary (compat)': 'B:\\\\mandg\\\\ESG_Deliverables\\\\ESG_Deliverables_with_Summary\\\\outputs\\\\cross_company_summary.csv',\n",
       " 'executive_summary (compat)': 'B:\\\\mandg\\\\ESG_Deliverables\\\\ESG_Deliverables_with_Summary\\\\outputs\\\\executive_summary.md',\n",
       " 'topic_briefs (compat)': 'B:\\\\mandg\\\\ESG_Deliverables\\\\ESG_Deliverables_with_Summary\\\\outputs\\\\topic_briefs.md'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from src.postprocess_summary import run_global_summary\n",
    "\n",
    "# Replace with your pipeline’s claims table path:\n",
    "# INPUT_CSV = \"B:\\mandg\\ESG_Deliverables\\ESG_Deliverables_with_Summary\\outputs\\final_claims_table.csv\"\n",
    "INPUT_CSV = r\"B:\\mandg\\ESG_Deliverables\\ESG_Deliverables_with_Summary\\outputs\\cross_company_esg_claim_summary.csv\"\n",
    "outputs = r\"B:\\mandg\\ESG_Deliverables\\ESG_Deliverables_with_Summary\\outputs\"\n",
    "\n",
    "paths = run_global_summary(INPUT_CSV, output_dir=outputs)\n",
    "paths  # shows generated file paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24dd9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
